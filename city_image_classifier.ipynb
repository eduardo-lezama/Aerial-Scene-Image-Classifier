{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9666d5ba30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path, transformations=None):\n",
    "        #Apply img transformations\n",
    "        self.transformations = transformations\n",
    "        #Load all images in a path\n",
    "        self.img_paths = [im_path for im_path in sorted(glob(f\"{path}/*/*\"))]\n",
    "        #Dictionaries and counters for classes and count per class\n",
    "        self.class_names = {}\n",
    "        self.class_counts = {}\n",
    "        count = 0\n",
    "\n",
    "        for idx, img_path in enumerate(self.img_paths):\n",
    "            #Get the class name\n",
    "            class_name = self.get_class(img_path)\n",
    "            #Check if the class exist already and if not appends it to the class name dict\n",
    "            if class_name not in self.class_names:\n",
    "                self.class_names[class_name] = count\n",
    "                self.class_counts[class_name] = 1\n",
    "                count += 1\n",
    "            #If it exist, increase the counter for that class\n",
    "            else:\n",
    "                self.class_counts[class_name] += 1\n",
    "\n",
    "    #Function to get the real label of an img\n",
    "    def get_class(self, path) -> str:\n",
    "        \"\"\"Return the name of the class based on its path\"\"\"\n",
    "        return os.path.dirname(path).split(\"/\")[-1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    #Obtain 1 image and its label from te ds\n",
    "    def __getitem__(self, idx: int):\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.class_names[self.get_class(img_path)]\n",
    "\n",
    "        #If there are tarnsformation, apply it to return the image with them.\n",
    "        if self.transformations is not None:\n",
    "            image = self.transformations(image)\n",
    "        return image, label\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(\"/home/edu_pc/Projects/Aer_City_Img_Classifier/dataset/\")\n",
    "print(len(dataset))\n",
    "\n",
    "a,b = dataset[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(path, transformations, batch_size, split: list = [0.9, 0.05, 0.05], num_workers: int = 4):\n",
    "    \"\"\"Organize and create the dataloaders for train, valid and test using our datset objet. Splits and apply transformations and\"\"\"\n",
    "    dataset = MyDataset(path = path, transformations=transformations)\n",
    "    #Calculate the len for each split (train, valid, test)\n",
    "    dataset_len = len(dataset)\n",
    "    train_len = int(dataset_len * split[0])\n",
    "    val_len = int(dataset_len * split[1])\n",
    "    test_len = int(dataset_len * split[2])\n",
    "\n",
    "    #Create the splits \n",
    "    tr_ds, val_ds, test_ds = random_split(dataset, lengths=[train_len, val_len, test_len])\n",
    "\n",
    "    #Create the dataloaders\n",
    "    tr_dl = DataLoader(dataset=tr_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers) \n",
    "    #Avoid shuffle for replicability in both val and test \n",
    "    val_dl = DataLoader(dataset=val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    #test images are evaluated 1 by 1  \n",
    "    test_dl = DataLoader(dataset=test_ds, batch_size=1, shuffle=False, num_workers=num_workers)  \n",
    "\n",
    "    #Return dataloaders for each split andthe class_names with its IDs (keys are the name, value the ID)\n",
    "    return tr_dl, val_dl, test_dl, dataset.class_names\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization dataset and dataloaders for our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"dataset\"\n",
    "\n",
    "#Normalization parameters per channel\n",
    "mean = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "resize = 224\n",
    "\n",
    "#Define the transformations using transforms utils\n",
    "    #Resize to 224x224\n",
    "    #Tranform to tensor\n",
    "    #Normalize according typical values of ConvNext, ResNet and so\n",
    "transforms = T.Compose([\n",
    "    T.Resize((resize,resize)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean = mean, std = std)]\n",
    ")\n",
    "\n",
    "#Create the dataloaders using our function\n",
    "tr_dl, val_dl, test_dl, classes = create_dataloaders(path=ds_path, transformations=transforms, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "13\n",
      "400\n",
      "{'Bridge': 0, 'Commercial': 1, 'Industrial': 2, 'Intersection': 3, 'Landmark': 4, 'Park': 5, 'Parking': 6, 'Playground': 7, 'Residential': 8, 'Stadium': 9}\n"
     ]
    }
   ],
   "source": [
    "#Check the batches per dataloader\n",
    "print(len(tr_dl)); print(len(val_dl)); print(len(test_dl)); print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the numbers are correct. We have 400 batches in the test_dl because we specified batch size of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
